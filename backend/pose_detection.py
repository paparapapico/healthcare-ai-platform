import cv2
import mediapipe as mp
import numpy as np
import time

class PoseDetector:
    """AI ìì„¸ ì¸ì‹ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.mp_pose = mp.solutions.pose
        self.pose = self.mp_pose.Pose(
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        self.mp_drawing = mp.solutions.drawing_utils
        
    def calculate_angle(self, a, b, c):
        """ì„¸ ì ì„ ì´ìš©í•œ ê°ë„ ê³„ì‚°"""
        a = np.array(a)  # ì²« ë²ˆì§¸ ì 
        b = np.array(b)  # ì¤‘ê°„ ì  (ê´€ì ˆ)
        c = np.array(c)  # ì„¸ ë²ˆì§¸ ì 
        
        radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
        angle = np.abs(radians*180.0/np.pi)
        
        if angle > 180.0:
            angle = 360-angle
            
        return angle
    
    def detect_squat(self, landmarks):
        """ìŠ¤ì¿¼íŠ¸ ìì„¸ ê°ì§€ ë° ë¶„ì„"""
        # ì£¼ìš” ê´€ì ˆ í¬ì¸íŠ¸ ì¶”ì¶œ
        hip = [landmarks[self.mp_pose.PoseLandmark.LEFT_HIP.value].x,
               landmarks[self.mp_pose.PoseLandmark.LEFT_HIP.value].y]
        knee = [landmarks[self.mp_pose.PoseLandmark.LEFT_KNEE.value].x,
                landmarks[self.mp_pose.PoseLandmark.LEFT_KNEE.value].y]
        ankle = [landmarks[self.mp_pose.PoseLandmark.LEFT_ANKLE.value].x,
                 landmarks[self.mp_pose.PoseLandmark.LEFT_ANKLE.value].y]
        
        # ë¬´ë¦ ê°ë„ ê³„ì‚°
        angle = self.calculate_angle(hip, knee, ankle)
        
        # ìŠ¤ì¿¼íŠ¸ ë‹¨ê³„ íŒì •
        squat_stage = None
        feedback = ""
        
        if angle > 160:
            squat_stage = "UP"
            feedback = "ì‹œì‘ ìì„¸ - ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤"
        elif angle < 90:
            squat_stage = "DOWN"
            feedback = "ì¢‹ìŠµë‹ˆë‹¤! ì¶©ë¶„íˆ ë‚´ë ¤ê°”ìŠµë‹ˆë‹¤"
        else:
            squat_stage = "MIDDLE"
            feedback = f"ë¬´ë¦ ê°ë„: {angle:.1f}Â° - ì¡°ê¸ˆ ë” ë‚´ë ¤ê°€ì„¸ìš”"
            
        return angle, squat_stage, feedback
    
    def run_webcam(self):
        """ì›¹ìº ìœ¼ë¡œ ì‹¤ì‹œê°„ ìì„¸ ë¶„ì„"""
        cap = cv2.VideoCapture(0)
        
        # ìŠ¤ì¿¼íŠ¸ ì¹´ìš´í„°
        counter = 0 
        stage = None
        
        # FPS ê³„ì‚°
        prev_time = 0
        
        print("ğŸ¥ ì›¹ìº  ì‹œì‘! 'q'ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.")
        print("ğŸ“Œ ìŠ¤ì¿¼íŠ¸ ìì„¸ë¥¼ ì·¨í•´ë³´ì„¸ìš”!")
        
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
                
            # BGRì„ RGBë¡œ ë³€í™˜
            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            image.flags.writeable = False
            
            # í¬ì¦ˆ ê°ì§€
            results = self.pose.process(image)
            
            # RGBë¥¼ BGRë¡œ ë‹¤ì‹œ ë³€í™˜
            image.flags.writeable = True
            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
            
            # FPS ê³„ì‚°
            curr_time = time.time()
            fps = 1 / (curr_time - prev_time) if prev_time != 0 else 0
            prev_time = curr_time
            
            try:
                landmarks = results.pose_landmarks.landmark
                
                # ìŠ¤ì¿¼íŠ¸ ê°ì§€
                angle, squat_stage, feedback = self.detect_squat(landmarks)
                
                # ì¹´ìš´í„° ë¡œì§
                if squat_stage == "DOWN" and stage == "UP":
                    stage = "DOWN"
                elif squat_stage == "UP" and stage == "DOWN":
                    counter += 1
                    stage = "UP"
                    print(f"âœ… ìŠ¤ì¿¼íŠ¸ ì™„ë£Œ! ì´ {counter}ê°œ")
                elif stage is None:
                    stage = squat_stage
                
                # í™”ë©´ì— ì •ë³´ í‘œì‹œ
                # ìƒíƒœ ë°•ìŠ¤
                cv2.rectangle(image, (0, 0), (350, 120), (245, 117, 16), -1)
                
                # ì¹´ìš´í„°
                cv2.putText(image, 'REPS', (15, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 1, cv2.LINE_AA)
                cv2.putText(image, str(counter), (15, 80),
                           cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2, cv2.LINE_AA)
                
                # ê°ë„
                cv2.putText(image, 'ANGLE', (120, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 1, cv2.LINE_AA)
                cv2.putText(image, f'{int(angle)}', (120, 80),
                           cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2, cv2.LINE_AA)
                
                # ìƒíƒœ
                cv2.putText(image, 'STAGE', (220, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 1, cv2.LINE_AA)
                cv2.putText(image, stage if stage else "", (220, 80),
                           cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 255, 255), 2, cv2.LINE_AA)
                
                # í”¼ë“œë°±
                cv2.rectangle(image, (0, 420), (640, 480), (0, 255, 0), -1)
                cv2.putText(image, feedback, (10, 455),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2, cv2.LINE_AA)
                
                # FPS í‘œì‹œ
                cv2.putText(image, f'FPS: {int(fps)}', (500, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)
                
            except:
                pass
            
            # í¬ì¦ˆ ìŠ¤ì¼ˆë ˆí†¤ ê·¸ë¦¬ê¸°
            if results.pose_landmarks:
                self.mp_drawing.draw_landmarks(
                    image, 
                    results.pose_landmarks,
                    self.mp_pose.POSE_CONNECTIONS,
                    self.mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),
                    self.mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)
                )
            
            # í™”ë©´ í‘œì‹œ
            cv2.imshow('AI Pose Detection - Squat Counter', image)
            
            # 'q' í‚¤ë¡œ ì¢…ë£Œ
            if cv2.waitKey(10) & 0xFF == ord('q'):
                break
        
        print(f"\nğŸ ìš´ë™ ì¢…ë£Œ!")
        print(f"ğŸ“Š ì´ ìŠ¤ì¿¼íŠ¸ ê°œìˆ˜: {counter}ê°œ")
        
        cap.release()
        cv2.destroyAllWindows()

def test_basic_detection():
    """ê¸°ë³¸ í¬ì¦ˆ ê°ì§€ í…ŒìŠ¤íŠ¸"""
    print("=" * 50)
    print("ğŸ¤– AI ìì„¸ ì¸ì‹ POC í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    mp_pose = mp.solutions.pose
    
    # ì •ì  ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸
    print("\n1. MediaPipe ì„¤ì¹˜ í™•ì¸... âœ…")
    print(f"   - MediaPipe ë²„ì „: {mp.__version__}")
    
    # OpenCV í…ŒìŠ¤íŠ¸
    print("\n2. OpenCV ì„¤ì¹˜ í™•ì¸... âœ…")
    print(f"   - OpenCV ë²„ì „: {cv2.__version__}")
    
    # ì¹´ë©”ë¼ ì—°ê²° í…ŒìŠ¤íŠ¸
    print("\n3. ì¹´ë©”ë¼ ì—°ê²° í…ŒìŠ¤íŠ¸...")
    cap = cv2.VideoCapture(0)
    if cap.isOpened():
        print("   - ì¹´ë©”ë¼ ì—°ê²° ì„±ê³µ! âœ…")
        cap.release()
    else:
        print("   - ì¹´ë©”ë¼ ì—°ê²° ì‹¤íŒ¨ âŒ")
        return False
    
    print("\nâœ¨ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! POC ì‹¤í–‰ ì¤€ë¹„ ì™„ë£Œ")
    return True

if __name__ == "__main__":
    # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    if test_basic_detection():
        print("\n" + "=" * 50)
        print("ğŸ¬ ì‹¤ì‹œê°„ ìŠ¤ì¿¼íŠ¸ ìì„¸ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤!")
        print("=" * 50)
        
        # í¬ì¦ˆ ê°ì§€ê¸° ì‹¤í–‰
        detector = PoseDetector()
        detector.run_webcam()
    else:
        print("\nâŒ í™˜ê²½ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        print("í•„ìš”í•œ íŒ¨í‚¤ì§€:")
        print("  pip install mediapipe opencv-python numpy")