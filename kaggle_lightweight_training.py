"""
Kaggle Lightweight Sports AI Training - ë©”ëª¨ë¦¬ ìµœì í™” ë²„ì „
Optimized for Kaggle P100 GPU (16GB VRAM)
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import numpy as np
import gc
import os
from datetime import datetime

print("=" * 60)
print("ğŸ† Sports AI Training - Lightweight Version")
print("=" * 60)

# GPU ì„¤ì • ë° ë©”ëª¨ë¦¬ ìµœì í™”
if torch.cuda.is_available():
    device = torch.device('cuda')
    torch.cuda.empty_cache()
    print(f"âœ… GPU: {torch.cuda.get_device_name(0)}")
    print(f"âœ… VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    
    # ë©”ëª¨ë¦¬ ì œí•œ ì„¤ì •
    torch.cuda.set_per_process_memory_fraction(0.8)
else:
    device = torch.device('cpu')
    print("âš ï¸ CPU mode")

# ============================================================================
# 1. ì´ˆê²½ëŸ‰ ëª¨ë¸ (ë©”ëª¨ë¦¬ ì‚¬ìš© ìµœì†Œí™”)
# ============================================================================

class LightweightSportsModel(nn.Module):
    """ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ê²½ëŸ‰ ëª¨ë¸"""
    
    def __init__(self):
        super().__init__()
        # ì‘ì€ ë„¤íŠ¸ì›Œí¬
        self.encoder = nn.Sequential(
            nn.Linear(51, 64),  # 17 keypoints * 3 = 51
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, 32),
            nn.ReLU()
        )
        
        self.classifier = nn.Linear(32, 4)  # 4 sports
        
    def forward(self, x):
        x = self.encoder(x)
        return self.classifier(x)

# ============================================================================
# 2. ì‘ì€ ë°ì´í„°ì…‹
# ============================================================================

class SmallDataset(Dataset):
    """ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì‘ì€ ë°ì´í„°ì…‹"""
    
    def __init__(self, size=1000):
        # ì‘ì€ í¬ê¸°ë¡œ ì‹œì‘
        self.data = torch.randn(size, 51)
        self.labels = torch.randint(0, 4, (size,))
        
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        return self.data[idx], self.labels[idx]

# ============================================================================
# 3. ë©”ì¸ í•™ìŠµ (ë©”ëª¨ë¦¬ ìµœì í™”)
# ============================================================================

def train_lightweight():
    """ê²½ëŸ‰ í•™ìŠµ í•¨ìˆ˜"""
    
    try:
        # 1. ëª¨ë¸ ìƒì„±
        print("\nğŸ“¦ ëª¨ë¸ ìƒì„± ì¤‘...")
        model = LightweightSportsModel().to(device)
        print(f"ëª¨ë¸ íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in model.parameters()):,}")
        
        # 2. ë°ì´í„° ì¤€ë¹„ (ì‘ì€ ë°°ì¹˜)
        print("\nğŸ“Š ë°ì´í„° ì¤€ë¹„ ì¤‘...")
        dataset = SmallDataset(size=500)  # ì‘ì€ ë°ì´í„°
        dataloader = DataLoader(
            dataset, 
            batch_size=8,  # ì‘ì€ ë°°ì¹˜
            shuffle=True,
            num_workers=0  # ë©”ëª¨ë¦¬ ì ˆì•½
        )
        
        # 3. ì˜µí‹°ë§ˆì´ì €
        optimizer = optim.Adam(model.parameters(), lr=0.001)
        criterion = nn.CrossEntropyLoss()
        
        # 4. í•™ìŠµ ì‹œì‘
        print("\nğŸš€ í•™ìŠµ ì‹œì‘!")
        print("-" * 40)
        
        for epoch in range(10):  # 10 ì—í­ë§Œ
            model.train()
            total_loss = 0
            correct = 0
            total = 0
            
            for batch_idx, (data, target) in enumerate(dataloader):
                # GPUë¡œ ì´ë™
                data = data.to(device)
                target = target.to(device)
                
                # Forward
                output = model(data)
                loss = criterion(output, target)
                
                # Backward
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                
                # í†µê³„
                total_loss += loss.item()
                _, predicted = output.max(1)
                total += target.size(0)
                correct += predicted.eq(target).sum().item()
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                if batch_idx % 10 == 0:
                    torch.cuda.empty_cache()
                    gc.collect()
            
            # ì—í­ ê²°ê³¼
            accuracy = 100. * correct / total
            avg_loss = total_loss / len(dataloader)
            print(f"Epoch {epoch+1}/10 | Loss: {avg_loss:.4f} | Acc: {accuracy:.2f}%")
            
            # ë©”ëª¨ë¦¬ ìƒíƒœ
            if device.type == 'cuda':
                allocated = torch.cuda.memory_allocated() / 1e9
                reserved = torch.cuda.memory_reserved() / 1e9
                print(f"  â””â”€ VRAM: {allocated:.2f}/{reserved:.2f} GB")
        
        # 5. ëª¨ë¸ ì €ì¥
        print("\nğŸ’¾ ëª¨ë¸ ì €ì¥ ì¤‘...")
        save_path = '/kaggle/working/lightweight_model.pth'
        torch.save({
            'model': model.state_dict(),
            'accuracy': accuracy,
            'timestamp': datetime.now().isoformat()
        }, save_path)
        print(f"âœ… ì €ì¥ ì™„ë£Œ: {save_path}")
        
        # 6. í…ŒìŠ¤íŠ¸
        print("\nğŸ§ª ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸...")
        model.eval()
        with torch.no_grad():
            test_input = torch.randn(1, 51).to(device)
            test_output = model(test_input)
            predicted_sport = test_output.argmax().item()
            sports = ['ë†êµ¬', 'ì¶•êµ¬', 'ê³¨í”„', 'ë§¨ëª¸ìš´ë™']
            print(f"ì˜ˆì¸¡ ê²°ê³¼: {sports[predicted_sport]}")
        
        print("\n" + "=" * 60)
        print("ğŸ‰ í•™ìŠµ ì™„ë£Œ!")
        print("=" * 60)
        
        return model
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("ë©”ëª¨ë¦¬ ì •ë¦¬ ì¤‘...")
        torch.cuda.empty_cache()
        gc.collect()
        
        # ë” ì‘ì€ ëª¨ë¸ë¡œ ì¬ì‹œë„
        print("\nğŸ”„ ë” ì‘ì€ ëª¨ë¸ë¡œ ì¬ì‹œë„...")
        return train_minimal()

def train_minimal():
    """ìµœì†Œ ëª¨ë¸ (ì˜¤ë¥˜ ì‹œ í´ë°±)"""
    
    print("\nğŸ¤ ìµœì†Œ ëª¨ë¸ ì‹¤í–‰...")
    
    # ì•„ì£¼ ì‘ì€ ëª¨ë¸
    model = nn.Sequential(
        nn.Linear(51, 16),
        nn.ReLU(),
        nn.Linear(16, 4)
    ).to(device)
    
    # ì•„ì£¼ ì‘ì€ ë°ì´í„°
    X = torch.randn(100, 51).to(device)
    y = torch.randint(0, 4, (100,)).to(device)
    
    # ê°„ë‹¨í•œ í•™ìŠµ
    optimizer = optim.SGD(model.parameters(), lr=0.01)
    criterion = nn.CrossEntropyLoss()
    
    for epoch in range(5):
        output = model(X)
        loss = criterion(output, y)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        print(f"Mini Epoch {epoch+1}: Loss {loss.item():.4f}")
    
    print("âœ… ìµœì†Œ í•™ìŠµ ì™„ë£Œ!")
    return model

# ============================================================================
# 4. ì‹¤í–‰
# ============================================================================

if __name__ == "__main__":
    # íŒ¨í‚¤ì§€ í™•ì¸
    print("\nğŸ“¦ íŒ¨í‚¤ì§€ ë²„ì „:")
    print(f"PyTorch: {torch.__version__}")
    
    # ë©”ëª¨ë¦¬ ì •ë¦¬
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    # í•™ìŠµ ì‹¤í–‰
    trained_model = train_lightweight()
    
    print("\nğŸ“Š ìµœì¢… ë©”ëª¨ë¦¬ ìƒíƒœ:")
    if torch.cuda.is_available():
        print(f"í• ë‹¹: {torch.cuda.memory_allocated()/1e9:.2f} GB")
        print(f"ì˜ˆì•½: {torch.cuda.memory_reserved()/1e9:.2f} GB")
    
    print("\nâœ¨ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")